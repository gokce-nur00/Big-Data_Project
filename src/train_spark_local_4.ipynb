{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CWg98Q3Ald01"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N2iDfcDmCKs",
        "outputId": "53014f35-0f18-4e60-cc73-9dfdbf1d9fc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd0nRgx_mEex",
        "outputId": "2877a34c-7c36-40f1-f01b-967b323256b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The following additional packages will be installed:\n",
            "  libxtst6 openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra fonts-nanum fonts-ipafont-gothic\n",
            "  fonts-ipafont-mincho fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 3 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 39.7 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 121666 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u392-ga-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u392-ga-1~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u392-ga-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u392-ga-1~22.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u392-ga-1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u392-ga-1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!apt install openjdk-8-jdk-headless -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eXy56nhYmMUt"
      },
      "outputs": [],
      "source": [
        "os.environ[\"JAVA_HOME\"]=\"/usr/lib/jvm/java-8-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh44iqFImPER",
        "outputId": "d82be0b6-5ac8-4d2e-c939-257987138d7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/lib/jvm/java-8-openjdk-amd64\n"
          ]
        }
      ],
      "source": [
        "!echo $JAVA_HOME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrJUJsTEmRlw",
        "outputId": "eded3334-e65e-44e0-84f2-0e7e35c5f519"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark==3.5.0\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark==3.5.0) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=15d693d790e55f010d14ba574eda58c0897b6ae4bc00e6dd07de032852c7d32e\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark==3.5.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bi9gK48KmbpP"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as f\n",
        "from pyspark.sql.functions import col, sum, when, isnan, lit\n",
        "from pyspark.sql.functions import monotonically_increasing_id\n",
        "from pyspark.sql import Row\n",
        "from pyspark.ml.linalg import Vectors, VectorUDT\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.sql.types import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WIcH146WmdWF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import psutil\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "NgOZcS8qmlLU"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.master(\"local[4]\").appName('ml-app-4').config('spark.ui.port', '4050').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "qbj28ihamvf_"
      },
      "outputs": [],
      "source": [
        "df = spark.read.csv('/content/train_full.csv',inferSchema=True,header=True)\n",
        "df_test = spark.read.csv('/content/test_full.csv',inferSchema=True,header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "GA9HzOlum5T4"
      },
      "outputs": [],
      "source": [
        "df = df.union(df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCVKKrGQm_hv",
        "outputId": "7fb5e7ff-02ba-490d-9d0f-39ddd45455c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(11306, 19)\n"
          ]
        }
      ],
      "source": [
        "print((df.count(),len(df.columns)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "gSrUeYAQnBoX"
      },
      "outputs": [],
      "source": [
        "def preprocess(data):\n",
        "  start_time = time.time()\n",
        "\n",
        "  data = data.withColumn(\"index\", monotonically_increasing_id())\n",
        "  data = data.drop(*['PassengerId', 'Name'])\n",
        "\n",
        "  bool_data = data.select([col(c).cast(\"integer\") for c in [\"CryoSleep\", \"VIP\", \"Transported\"]])\n",
        "  bool_data = bool_data.withColumn(\"index\", monotonically_increasing_id())\n",
        "\n",
        "  bool_data = bool_data.withColumnRenamed(\"CryoSleep\", \"CryoSleep_value\")\n",
        "  bool_data = bool_data.withColumnRenamed(\"VIP\", \"VIP_value\")\n",
        "  bool_data = bool_data.withColumnRenamed(\"Transported\", \"Transported_value\")\n",
        "\n",
        "  combined_data = data.join(bool_data, on=\"index\", how=\"inner\")\n",
        "\n",
        "  SI_HomePlanet = StringIndexer(inputCol='HomePlanet',outputCol='HomePlanet_Index')\n",
        "  SI_Destination = StringIndexer(inputCol='Destination',outputCol='Destination_Index')\n",
        "  SI_Lastname = StringIndexer(inputCol='Lastname',outputCol='Lastname_Index')\n",
        "  SI_Deck = StringIndexer(inputCol='Deck',outputCol='Deck_Index')\n",
        "  SI_Deck_side = StringIndexer(inputCol='Deck_side',outputCol='DeckSide_Index')\n",
        "  ST_VRDeck = StringIndexer(inputCol=\"VRDeck\", outputCol=\"VRDeck_index\")\n",
        "  ST_ShoppingMall = StringIndexer(inputCol=\"ShoppingMall\", outputCol=\"ShoppingMall_index\")\n",
        "  ST_RoomService = StringIndexer(inputCol=\"RoomService\", outputCol=\"RoomService_index\")\n",
        "  ST_Age = StringIndexer(inputCol=\"Age\", outputCol=\"Age_index\")\n",
        "  ST_FoodCourt = StringIndexer(inputCol=\"FoodCourt\", outputCol=\"FoodCourt_index\")\n",
        "  ST_Spa = StringIndexer(inputCol=\"Spa\", outputCol=\"Spa_index\")\n",
        "\n",
        "  st = [SI_HomePlanet, SI_Destination, SI_Lastname, SI_Deck, SI_Deck_side, ST_VRDeck, ST_ShoppingMall, ST_RoomService, ST_Age, ST_FoodCourt, ST_Spa]\n",
        "\n",
        "  for indexer in st:\n",
        "    combined_data = indexer.fit(combined_data).transform(combined_data)\n",
        "\n",
        "  pandas_df = combined_data.toPandas()\n",
        "\n",
        "  combined_data = combined_data.withColumn(\n",
        "    \"RoomService_index\",\n",
        "    when(combined_data.RoomService_index > 9000, 9000).otherwise(combined_data.RoomService_index)\n",
        "  )\n",
        "  combined_data = combined_data.withColumn(\n",
        "      \"FoodCourt_index\",\n",
        "      when(combined_data.FoodCourt_index > 22000, 22000).otherwise(combined_data.RoomService_index)\n",
        "  )\n",
        "  combined_data = combined_data.withColumn(\n",
        "      \"ShoppingMall_index\",\n",
        "      when(combined_data.ShoppingMall_index > 11000, 11000).otherwise(combined_data.RoomService_index)\n",
        "  )\n",
        "  combined_data = combined_data.withColumn(\n",
        "      \"Spa_index\",\n",
        "      when(combined_data.Spa_index > 17000, 17000).otherwise(combined_data.RoomService_index)\n",
        "  )\n",
        "  combined_data = combined_data.withColumn(\n",
        "      \"VRDeck_index\",\n",
        "      when(combined_data.VRDeck_index > 21000, 21000).otherwise(combined_data.RoomService_index)\n",
        "  )\n",
        "\n",
        "  services = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n",
        "  pandas_df['Total_expenses'] = pandas_df[services].sum(axis=1)\n",
        "  Group_members = pandas_df.Group.value_counts().to_dict()\n",
        "  pandas_df['Group_members'] = pandas_df.Group.map(Group_members)\n",
        "  Cabin_members = pandas_df.Cabin.value_counts().to_dict()\n",
        "  pandas_df['Cabin_members'] = pandas_df.Cabin.map(Cabin_members)\n",
        "\n",
        "  pandas_df.Cabin_members.fillna(pandas_df.Cabin_members.mean(), inplace=True)\n",
        "  col_drop = ['Cabin', 'Lastname']\n",
        "  pandas_df = pandas_df.drop(col_drop, axis=1)\n",
        "\n",
        "  spark_df = spark.createDataFrame(pandas_df)\n",
        "\n",
        "  OHE = OneHotEncoder(inputCols=['Age_index', 'RoomService_index','FoodCourt_index','ShoppingMall_index','Spa_index','VRDeck_index','Group', \"Cab_num\", \"HomePlanet_Index\", \"Destination_Index\" , \"Lastname_Index\", \"Deck_Index\", \"DeckSide_Index\", \"CryoSleep_value\", \"VIP_value\"],\n",
        "                    outputCols=['Age_index_OHE', 'RoomService_index_OHE','FoodCourt_index_OHE','ShoppingMall_index_OHE','Spa_index_OHE','VRDeck_index_OHE','Group_OHE', \"Cab_num_OHE\", \"HomePlanet_Index_OHE\", \"Destination_Index_OHE\" , \"Lastname_Index_OHE\", \"Deck_Index_OHE\",\n",
        "                                \"DeckSide_Index_OHE\", \"CryoSleep_value_OHE\", \"VIP_value_OHE\"])\n",
        "\n",
        "  combined_OHE_data = OHE.fit(spark_df).transform(spark_df)\n",
        "\n",
        "  assembler = VectorAssembler(inputCols=[\n",
        " 'Age',\n",
        " 'RoomService',\n",
        " 'FoodCourt',\n",
        " 'ShoppingMall',\n",
        " 'Spa',\n",
        " 'VRDeck',\n",
        " 'Group',\n",
        " 'Cab_num',\n",
        " 'HomePlanet_Index',\n",
        " 'Destination_Index',\n",
        " 'Lastname_Index',\n",
        " 'Deck_Index',\n",
        " 'DeckSide_Index',\n",
        " 'CryoSleep_value',\n",
        " 'VIP_value',\n",
        " 'HomePlanet_Index_OHE',\n",
        " 'Destination_Index_OHE',\n",
        " 'Lastname_Index_OHE',\n",
        " 'Deck_Index_OHE',\n",
        " 'DeckSide_Index_OHE',\n",
        " 'CryoSleep_value_OHE',\n",
        " 'VIP_value_OHE'],\n",
        "                           outputCol='features')\n",
        "\n",
        "  data = combined_OHE_data.fillna(0)\n",
        "  data = assembler.transform(data)\n",
        "  model_df = data.select([\"features\", \"Transported_value\"])\n",
        "  model_df = model_df.withColumnRenamed(\"Transported_value\",\"label\")\n",
        "\n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "  cpu_percent = psutil.cpu_percent()\n",
        "  virtual_memory_percent = psutil.virtual_memory().percent\n",
        "  return [model_df, {\n",
        "        'elapsed_time': elapsed_time,\n",
        "        'cpu_percent': cpu_percent,\n",
        "        'virtual_memory_percent': virtual_memory_percent\n",
        "    }]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "5dCNH7BZqMhF"
      },
      "outputs": [],
      "source": [
        "r = preprocess(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "2MbsrxS0qQTS"
      },
      "outputs": [],
      "source": [
        "preprocessed_data = r[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-h09k70qZpb",
        "outputId": "3c056aff-2f05-437f-8c0c-f0199bb91768"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|            features|label|\n",
            "+--------------------+-----+\n",
            "|(2407,[0,6,8,10,1...|    0|\n",
            "|(2407,[0,1,2,3,4,...|    1|\n",
            "|(2407,[0,1,2,4,5,...|    0|\n",
            "|(2407,[0,2,3,4,5,...|    0|\n",
            "|(2407,[0,1,2,3,4,...|    1|\n",
            "+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "preprocessed_data.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "neictX32qhXk"
      },
      "outputs": [],
      "source": [
        "preprocessing_per = r[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Shlp9kbqoqq",
        "outputId": "bf8050bb-defb-462c-85bb-10413a098079"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'elapsed_time': 12.976667642593384,\n",
              " 'cpu_percent': 56.0,\n",
              " 'virtual_memory_percent': 18.3}"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preprocessing_per"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "6D9NEh22qqw8"
      },
      "outputs": [],
      "source": [
        "def train(data):\n",
        "  start_time = time.time()\n",
        "\n",
        "  training_df,test_df = data.randomSplit([0.75,0.25])\n",
        "  log_reg = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "\n",
        "  log_reg_model = log_reg.fit(training_df)\n",
        "  lr_summary=log_reg_model.summary\n",
        "\n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "  cpu_percent = psutil.cpu_percent()\n",
        "  virtual_memory_percent = psutil.virtual_memory().percent\n",
        "\n",
        "  return{\n",
        "        'accuracy' : lr_summary.accuracy,\n",
        "        'ROC' : lr_summary.areaUnderROC,\n",
        "        'elapsed_time': elapsed_time,\n",
        "        'cpu_percent': cpu_percent,\n",
        "        'virtual_memory_percent': virtual_memory_percent\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "J-3v-_rNracR"
      },
      "outputs": [],
      "source": [
        "t = train(preprocessed_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eW4xCkVUrfcM",
        "outputId": "4193cf50-4560-4230-919b-8e438dcb64a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.8346512451315945,\n",
              " 'ROC': 0.9165465142291688,\n",
              " 'elapsed_time': 7.704815149307251,\n",
              " 'cpu_percent': 33.0,\n",
              " 'virtual_memory_percent': 18.7}"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ilHwZBGrlRb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
